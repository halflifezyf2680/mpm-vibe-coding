package services

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"runtime"
	"strconv"
	"strings"
	"sync"
	"time"

	_ "modernc.org/sqlite"
)

// ============================================================================
// æ•°æ®ç»“æ„ - ä¸ Rust ast_indexer è¾“å‡ºæ ¼å¼åŒ¹é…
// ============================================================================

// Node ç¬¦å·èŠ‚ç‚¹
type Node struct {
	ID            string   `json:"id"`
	NodeType      string   `json:"type"`
	Name          string   `json:"name"`
	QualifiedName string   `json:"qualified_name"`
	ScopePath     string   `json:"scope_path,omitempty"`
	FilePath      string   `json:"file_path"`
	LineStart     int      `json:"line_start"`
	LineEnd       int      `json:"line_end"`
	Signature     string   `json:"signature,omitempty"`
	Calls         []string `json:"calls,omitempty"`
}

// Stats ç»Ÿè®¡ä¿¡æ¯
type Stats struct {
	TotalFiles   int `json:"total_files"`
	TotalSymbols int `json:"total_symbols"`
}

// MapResult é¡¹ç›®åœ°å›¾ç»“æœ (--mode map)
type MapResult struct {
	Statistics    Stats              `json:"statistics"`
	Structure     map[string][]Node  `json:"structure"`
	Elapsed       string             `json:"elapsed"`
	ComplexityMap map[string]float64 `json:"complexity_map,omitempty"` // ç¬¦å·å -> å¤æ‚åº¦åˆ†æ•°
}

// StructureDirInfo ç›®å½•ç»“æ„ä¿¡æ¯ï¼ˆ--mode structureï¼‰
type StructureDirInfo struct {
	FileCount int      `json:"file_count"`
	Files     []string `json:"files"`
}

// StructureResult ç›®å½•ç»“æ„ç»“æœï¼ˆ--mode structureï¼‰
type StructureResult struct {
	Status     string                      `json:"status"`
	TotalFiles int                         `json:"total_files"`
	Structure  map[string]StructureDirInfo `json:"structure"`
}

// CandidateMatch å€™é€‰åŒ¹é…
type CandidateMatch struct {
	Node      Node    `json:"node"`
	MatchType string  `json:"match_type"`
	Score     float32 `json:"score"`
}

// CallerInfo è°ƒç”¨è€…ä¿¡æ¯
type CallerInfo struct {
	Node     Node   `json:"node"`
	CallType string `json:"call_type"`
}

// QueryResult æŸ¥è¯¢ç»“æœ (--mode query)
type QueryResult struct {
	Status       string           `json:"status"`
	Query        string           `json:"query"`
	FoundSymbol  *Node            `json:"found_symbol"`
	MatchType    string           `json:"match_type,omitempty"`
	Candidates   []CandidateMatch `json:"candidates"`
	RelatedNodes []CallerInfo     `json:"related_nodes"`
}

// ImpactResult å½±å“åˆ†æç»“æœ (--mode analyze)
type ImpactResult struct {
	Status                string       `json:"status"`
	NodeID                string       `json:"node_id"`
	ComplexityScore       float64      `json:"complexity_score"`
	ComplexityLevel       string       `json:"complexity_level"`
	RiskLevel             string       `json:"risk_level"`
	AffectedNodes         int          `json:"affected_nodes"`
	DirectCallers         []CallerInfo `json:"direct_callers"`
	IndirectCallers       []CallerInfo `json:"indirect_callers"`
	ModificationChecklist []string     `json:"modification_checklist"`
	Message               string       `json:"message,omitempty"`
}

// IndexResult ç´¢å¼•ç»“æœ (--mode index)
type IndexResult struct {
	Status       string `json:"status"`
	TotalFiles   int    `json:"total_files"`
	ParsedFiles  int    `json:"parsed_files,omitempty"`
	MetaFiles    int    `json:"meta_files,omitempty"`
	SkippedFiles int    `json:"skipped_files,omitempty"`
	Strategy     string `json:"strategy,omitempty"`
	ElapsedMs    int64  `json:"elapsed_ms"`
}

// NamingAnalysis å‘½åé£æ ¼åˆ†æç»“æœ
type NamingAnalysis struct {
	FileCount      int      `json:"file_count"`
	SymbolCount    int      `json:"symbol_count"`
	DominantStyle  string   `json:"dominant_style"` // snake_case / camelCase / mixed
	SnakeCasePct   string   `json:"snake_case_pct"`
	CamelCasePct   string   `json:"camel_case_pct"`
	ClassStyle     string   `json:"class_style"` // PascalCase
	CommonPrefixes []string `json:"common_prefixes"`
	SampleNames    []string `json:"sample_names"` // æ ·ä¾‹ å‡½æ•°å
	IsNewProject   bool     `json:"is_new_project"`
}

// ============================================================================
// ASTIndexer æ ¸å¿ƒæœåŠ¡
// ============================================================================

// ASTIndexer AST ç´¢å¼•å™¨æœåŠ¡
type ASTIndexer struct {
	BinaryPath  string
	indexMu     sync.Mutex
	lastIndexAt map[string]time.Time
}

const defaultIndexFreshness = 5 * time.Minute
const defaultIndexCommandTimeout = 30 * time.Minute

// NewASTIndexer åˆ›å»º AST ç´¢å¼•å™¨
func NewASTIndexer() *ASTIndexer {
	newIndexer := func(path string) *ASTIndexer {
		return &ASTIndexer{
			BinaryPath:  path,
			lastIndexAt: make(map[string]time.Time),
		}
	}

	exeName := "ast_indexer.exe"
	if runtime.GOOS != "windows" {
		exeName = "ast_indexer"
	}

	// è·å–å½“å‰å¯æ‰§è¡Œæ–‡ä»¶æ‰€åœ¨ç›®å½•
	execPath, err := os.Executable()
	if err == nil {
		execDir := filepath.Dir(execPath)
		// å°è¯•åœ¨åŒçº§ bin ç›®å½•æŸ¥æ‰¾
		binPath := filepath.Join(execDir, "bin", exeName)
		if fileExists(binPath) {
			return newIndexer(binPath)
		}
		// å°è¯•åŒçº§ç›®å½•
		sameDirPath := filepath.Join(execDir, exeName)
		if fileExists(sameDirPath) {
			return newIndexer(sameDirPath)
		}
	}

	// å…œåº•ï¼šå°è¯•ç›¸å¯¹è·¯å¾„
	paths := []string{
		filepath.Join("bin", exeName),
		filepath.Join("mcp-server-go", "bin", exeName),
	}

	for _, p := range paths {
		abs, _ := filepath.Abs(p)
		if fileExists(abs) {
			return newIndexer(abs)
		}
	}

	return newIndexer(exeName)
}

func normalizeProjectRoot(projectRoot string) string {
	absRoot, err := filepath.Abs(projectRoot)
	if err != nil {
		return projectRoot
	}
	return absRoot
}

func getIndexCommandTimeout() time.Duration {
	raw := strings.TrimSpace(os.Getenv("MPM_AST_INDEX_TIMEOUT_SECONDS"))
	if raw == "" {
		return defaultIndexCommandTimeout
	}
	sec, err := strconv.Atoi(raw)
	if err != nil || sec <= 0 {
		return defaultIndexCommandTimeout
	}
	return time.Duration(sec) * time.Second
}

func (ai *ASTIndexer) markIndexFresh(projectRoot string) {
	root := normalizeProjectRoot(projectRoot)
	ai.indexMu.Lock()
	ai.lastIndexAt[root] = time.Now()
	ai.indexMu.Unlock()
}

func (ai *ASTIndexer) shouldSkipIndex(projectRoot string, maxAge time.Duration) bool {
	root := normalizeProjectRoot(projectRoot)

	ai.indexMu.Lock()
	if ts, ok := ai.lastIndexAt[root]; ok && time.Since(ts) < maxAge {
		ai.indexMu.Unlock()
		return true
	}
	ai.indexMu.Unlock()

	info, err := os.Stat(getDBPath(root))
	if err != nil {
		return false
	}
	if time.Since(info.ModTime()) >= maxAge {
		return false
	}

	if !hasUsableIndex(getDBPath(root)) {
		return false
	}

	ai.indexMu.Lock()
	ai.lastIndexAt[root] = time.Now()
	ai.indexMu.Unlock()
	return true
}

func (ai *ASTIndexer) EnsureFreshIndex(projectRoot string) (*IndexResult, error) {
	if ai.shouldSkipIndex(projectRoot, defaultIndexFreshness) {
		return &IndexResult{Status: "cached"}, nil
	}
	return ai.Index(projectRoot)
}

func hasUsableIndex(dbPath string) bool {
	info, err := os.Stat(dbPath)
	if err != nil || info.Size() <= 0 {
		return false
	}

	db, err := sql.Open("sqlite", dbPath)
	if err != nil {
		return false
	}
	defer db.Close()

	var filesTableCount int
	if err := db.QueryRow("SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name='files'").Scan(&filesTableCount); err != nil {
		return false
	}
	if filesTableCount == 0 {
		return false
	}

	var fileCount int
	if err := db.QueryRow("SELECT COUNT(*) FROM files").Scan(&fileCount); err != nil {
		return false
	}

	return fileCount > 0
}

func fileExists(path string) bool {
	_, err := os.Stat(path)
	return err == nil
}

// getDBPath è·å–æ•°æ®åº“è·¯å¾„
func getDBPath(projectRoot string) string {
	// ã€ä¿®å¤ã€‘ç¡®ä¿è¿”å›ç»å¯¹è·¯å¾„,é˜²æ­¢Rustå¼•æ“å°†æ–‡ä»¶å†™åˆ°é”™è¯¯ä½ç½®
	absRoot, err := filepath.Abs(projectRoot)
	if err != nil {
		// å¦‚æœè½¬æ¢å¤±è´¥,ä½¿ç”¨åŸè·¯å¾„(ä½†å¯èƒ½æœ‰é£é™©)
		absRoot = projectRoot
	}
	return filepath.Join(absRoot, ".mcp-data", "symbols.db")
}

// getOutputPath è·å–ä¸´æ—¶è¾“å‡ºè·¯å¾„
func getOutputPath(projectRoot string, mode string) string {
	// ã€ä¿®å¤ã€‘ç¡®ä¿è¿”å›ç»å¯¹è·¯å¾„,é˜²æ­¢ç¼“å­˜æ–‡ä»¶è·‘åˆ°Cç›˜
	absRoot, err := filepath.Abs(projectRoot)
	if err != nil {
		// å¦‚æœè½¬æ¢å¤±è´¥,ä½¿ç”¨åŸè·¯å¾„(ä½†å¯èƒ½æœ‰é£é™©)
		absRoot = projectRoot
	}
	mcpData := filepath.Join(absRoot, ".mcp-data")
	_ = os.MkdirAll(mcpData, 0755)
	return filepath.Join(mcpData, fmt.Sprintf(".ast_result_%s.json", mode))
}

// ============================================================================
// æŠ€æœ¯æ ˆæ£€æµ‹ä¸è¿‡æ»¤é…ç½® (ç§»æ¤è‡ª ast_indexer_helper.py)
// ============================================================================

// detectTechStackAndConfig æ™ºèƒ½æ£€æµ‹æŠ€æœ¯æ ˆï¼Œè¿”å›(å…è®¸çš„æ‰©å±•å, å¿½ç•¥çš„ç›®å½•)
func detectTechStackAndConfig(projectRoot string) (extensions string, ignoreDirs string) {
	var stackDetected []string
	var exts []string

	// åŸºç¡€å¿½ç•¥ç›®å½•
	ignores := []string{
		".git", "__pycache__", "node_modules", ".venv", "venv",
		"dist", "build", ".idea", ".vscode",
		"release", "releases", "archive", "backup", "old",
	}

	// ä» .gitignore è§£æé¢å¤–çš„å¿½ç•¥ç›®å½•
	gitignoreDirs := parseGitignoreDirs(projectRoot)
	ignores = append(ignores, gitignoreDirs...)

	// ä¸€æ¬¡æ€§é€’å½’æ‰«ææ–‡ä»¶æ‰©å±•åï¼Œé¿å…åªçœ‹æ ¹ç›®å½•å¯¼è‡´è¯¯åˆ¤
	extSet := scanProjectExtensions(projectRoot, ignores, 8)
	hasExt := func(ext string) bool {
		ext = strings.TrimPrefix(strings.ToLower(ext), ".")
		return extSet[ext]
	}

	// 1. æ£€æµ‹ Python
	if fileExists(filepath.Join(projectRoot, "requirements.txt")) ||
		fileExists(filepath.Join(projectRoot, "pyproject.toml")) ||
		hasExt(".py") {
		stackDetected = append(stackDetected, "python")
		exts = append(exts, ".py")
		ignores = append(ignores, "site-packages", "htmlcov", ".pytest_cache")
	}

	// 2. æ£€æµ‹ Frontend (Node/React/Vue)
	if fileExists(filepath.Join(projectRoot, "package.json")) ||
		hasExt(".js") || hasExt(".jsx") || hasExt(".ts") || hasExt(".tsx") || hasExt(".vue") || hasExt(".svelte") {
		stackDetected = append(stackDetected, "frontend")
		exts = append(exts, ".js", ".jsx", ".ts", ".tsx", ".vue", ".svelte", ".css", ".html")
		ignores = append(ignores, "coverage", ".next", ".nuxt", "out")
	}

	// 3. æ£€æµ‹ Go
	if fileExists(filepath.Join(projectRoot, "go.mod")) || hasExt(".go") {
		stackDetected = append(stackDetected, "go")
		exts = append(exts, ".go")
		ignores = append(ignores, "vendor", "bin")
	}

	// 4. æ£€æµ‹ Rust (é€’å½’æœç´¢)
	if hasRustProject(projectRoot) || hasExt(".rs") {
		stackDetected = append(stackDetected, "rust")
		exts = append(exts, ".rs")
		ignores = append(ignores, "target")
	}

	// 5. æ£€æµ‹ C/C++
	if hasExt(".c") || hasExt(".cpp") || hasExt(".h") || hasExt(".hpp") || hasExt(".cc") ||
		fileExists(filepath.Join(projectRoot, "CMakeLists.txt")) {
		stackDetected = append(stackDetected, "cpp")
		exts = append(exts, ".c", ".h", ".cpp", ".hpp", ".cc")
		ignores = append(ignores, "cmake-build-debug", "obj")
	}

	// 6. æ£€æµ‹ Java
	if hasExt(".java") || fileExists(filepath.Join(projectRoot, "pom.xml")) ||
		fileExists(filepath.Join(projectRoot, "build.gradle")) {
		stackDetected = append(stackDetected, "java")
		exts = append(exts, ".java")
		ignores = append(ignores, ".gradle")
	}

	// å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç‰¹å®šæ ˆï¼Œä¸é™åˆ¶æ‰©å±•å
	if len(stackDetected) == 0 {
		return "", uniqueJoin(ignores)
	}

	return uniqueJoin(exts), uniqueJoin(ignores)
}

// scanProjectExtensions é€’å½’æ‰«æé¡¹ç›®å†…å‡ºç°è¿‡çš„æ‰©å±•å
func scanProjectExtensions(projectRoot string, ignoreDirs []string, maxDepth int) map[string]bool {
	result := make(map[string]bool)
	ignoreSet := make(map[string]bool)

	for _, dir := range ignoreDirs {
		d := strings.TrimSpace(strings.ToLower(strings.Trim(dir, "/\\")))
		if d != "" {
			ignoreSet[d] = true
		}
	}

	var walk func(dir string, depth int)
	walk = func(dir string, depth int) {
		if depth > maxDepth {
			return
		}

		entries, err := os.ReadDir(dir)
		if err != nil {
			return
		}

		for _, e := range entries {
			name := e.Name()
			nameLower := strings.ToLower(name)

			if e.IsDir() {
				if shouldSkipDetectDir(nameLower, ignoreSet) {
					continue
				}
				walk(filepath.Join(dir, name), depth+1)
				continue
			}

			ext := strings.TrimPrefix(strings.ToLower(filepath.Ext(name)), ".")
			if ext != "" {
				result[ext] = true
			}
		}
	}

	walk(projectRoot, 0)
	return result
}

func shouldSkipDetectDir(name string, ignoreSet map[string]bool) bool {
	if ignoreSet[name] {
		return true
	}

	switch name {
	case ".git", "node_modules", "vendor", "target", "dist", "build", "coverage", ".next", ".nuxt", "out",
		"__pycache__", ".pytest_cache", ".venv", "venv", "site-packages", ".idea", ".vscode", ".mcp-data",
		"release", "releases", "archive", "backup", "old":
		return true
	default:
		return false
	}
}

// parseGitignoreDirs è§£æ .gitignore æ–‡ä»¶ï¼Œæå–ç›®å½•å¿½ç•¥è§„åˆ™
func parseGitignoreDirs(projectRoot string) []string {
	gitignorePath := filepath.Join(projectRoot, ".gitignore")
	data, err := os.ReadFile(gitignorePath)
	if err != nil {
		return nil
	}

	var ignoredDirs []string
	fileExtensions := map[string]bool{
		"txt": true, "md": true, "json": true, "yml": true, "yaml": true,
		"toml": true, "lock": true, "log": true, "py": true, "js": true,
		"ts": true, "rs": true, "go": true, "java": true, "c": true,
		"cpp": true, "h": true, "hpp": true, "sql": true, "db": true,
	}

	lines := strings.Split(string(data), "\n")
	for _, line := range lines {
		line = strings.TrimSpace(line)

		// è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
		if line == "" || strings.HasPrefix(line, "#") {
			continue
		}
		// è·³è¿‡å¦å®šè§„åˆ™
		if strings.HasPrefix(line, "!") {
			continue
		}

		// ä¼˜å…ˆçº§ 1: ä»¥ / ç»“å°¾çš„æ˜ç¡®ç›®å½•
		if strings.HasSuffix(line, "/") {
			dirName := strings.TrimSuffix(line, "/")
			dirName = strings.TrimPrefix(dirName, "/")
			dirName = strings.ReplaceAll(dirName, "**/", "")
			if dirName != "" && !strings.HasPrefix(dirName, "**") {
				ignoredDirs = append(ignoredDirs, dirName)
			}
			continue
		}

		// ä¼˜å…ˆçº§ 2: åŒ…å« / çš„è·¯å¾„æ¨¡å¼
		if strings.Contains(line, "/") {
			parts := strings.Split(line, "/")
			pathPart := strings.ReplaceAll(parts[len(parts)-1], "*", "")
			if pathPart != "" && !strings.HasPrefix(pathPart, "**") {
				// æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ–‡ä»¶åï¼ˆåŒ…å«æ‰©å±•åï¼‰
				if strings.Contains(pathPart, ".") {
					extParts := strings.Split(pathPart, ".")
					ext := strings.ToLower(extParts[len(extParts)-1])
					if fileExtensions[ext] {
						continue
					}
				}
				ignoredDirs = append(ignoredDirs, pathPart)
			}
		}
	}

	return ignoredDirs
}

// hasFilesWithExt æ£€æŸ¥ç›®å½•ä¸‹æ˜¯å¦æœ‰æŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶
func hasFilesWithExt(dir string, ext string) bool {
	extSet := scanProjectExtensions(dir, nil, 8)
	ext = strings.TrimPrefix(strings.ToLower(ext), ".")
	return extSet[ext]
}

// hasRustProject é€’å½’æ£€æŸ¥æ˜¯å¦æœ‰ Rust é¡¹ç›®
func hasRustProject(projectRoot string) bool {
	if fileExists(filepath.Join(projectRoot, "Cargo.toml")) {
		return true
	}
	// é€’å½’æœç´¢å­ç›®å½•ï¼ˆæœ€å¤š6å±‚ï¼‰
	return hasCargoTomlRecursive(projectRoot, 0, 6)
}

func hasCargoTomlRecursive(dir string, depth, maxDepth int) bool {
	if depth >= maxDepth {
		return false
	}
	entries, err := os.ReadDir(dir)
	if err != nil {
		return false
	}
	for _, e := range entries {
		if e.IsDir() {
			subdir := filepath.Join(dir, e.Name())
			if fileExists(filepath.Join(subdir, "Cargo.toml")) {
				return true
			}
			if hasCargoTomlRecursive(subdir, depth+1, maxDepth) {
				return true
			}
		}
	}
	return false
}

// uniqueJoin å»é‡å¹¶ç”¨é€—å·è¿æ¥
func uniqueJoin(items []string) string {
	seen := make(map[string]bool)
	var result []string
	for _, item := range items {
		item = strings.TrimPrefix(item, ".")
		if item != "" && !seen[item] {
			seen[item] = true
			result = append(result, item)
		}
	}
	return strings.Join(result, ",")
}

// ============================================================================
// æ ¸å¿ƒæ–¹æ³•

// ============================================================================

// MapProject ç»˜åˆ¶é¡¹ç›®åœ°å›¾ (--mode map)
func (ai *ASTIndexer) MapProject(projectRoot string, detail string) (*MapResult, error) {
	return ai.MapProjectWithScope(projectRoot, detail, "")
}

// StructureProjectWithScope å¿«é€Ÿç›®å½•ç»“æ„æ‰«æï¼ˆ--mode structureï¼Œä¸ä¾èµ–ç¬¦å·ç´¢å¼•ï¼‰
func (ai *ASTIndexer) StructureProjectWithScope(projectRoot string, scope string) (*StructureResult, error) {
	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, "structure")
	_, ignoreDirs := detectTechStackAndConfig(projectRoot)

	_ = os.Remove(outputPath)

	if scope == "." || scope == "./" {
		scope = ""
	}

	args := []string{
		"--mode", "structure",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
		"--detail", "standard",
	}
	if scope != "" {
		args = append(args, "--scope", scope)
	}
	if ignoreDirs != "" {
		args = append(args, "--ignore-dirs", ignoreDirs)
	}

	cmd := exec.Command(ai.BinaryPath, args...)
	cmd.Dir = projectRoot
	output, err := cmd.CombinedOutput()
	if err != nil {
		msg := strings.TrimSpace(string(output))
		if msg != "" {
			return nil, fmt.Errorf("ç›®å½•ç»“æ„æ‰«æå¤±è´¥: %v: %s", err, msg)
		}
		return nil, fmt.Errorf("ç›®å½•ç»“æ„æ‰«æå¤±è´¥: %v", err)
	}

	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–ç›®å½•ç»“æ„ç»“æœå¤±è´¥: %v", err)
	}

	var result StructureResult
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("è§£æç›®å½•ç»“æ„ç»“æœå¤±è´¥: %v", err)
	}

	return &result, nil
}

// MapProjectWithScope å¸¦èŒƒå›´çš„é¡¹ç›®åœ°å›¾
func (ai *ASTIndexer) MapProjectWithScope(projectRoot string, detail string, scope string) (*MapResult, error) {
	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, "map")

	// æ¸…ç†æ—§æ–‡ä»¶
	_ = os.Remove(outputPath)

	// æ™ºèƒ½æŠ€æœ¯æ ˆæ£€æµ‹
	_, ignoreDirs := detectTechStackAndConfig(projectRoot)

	// å¦‚æœ scope æ˜¯ "." æˆ– "./"ï¼Œæ¸…ç†æ‰ï¼Œè®© Rust å¼•æ“æ‰§è¡Œå…¨é‡æ‰«æ
	if scope == "." || scope == "./" {
		scope = ""
	}

	args := []string{
		"--mode", "map",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
		"--detail", detail,
	}
	if scope != "" {
		args = append(args, "--scope", scope)
	}
	// å…è®¸ Rust å¼•æ“è‡ªåŠ¨æ¢æµ‹æ‰€æœ‰è¯­è¨€ï¼Œé™¤éæ˜ç¡®æŒ‡å®šï¼ˆæš‚ä¸è‡ªåŠ¨é™å®šï¼‰
	// if exts != "" {
	// 	args = append(args, "--extensions", exts)
	// }
	if ignoreDirs != "" {
		args = append(args, "--ignore-dirs", ignoreDirs)
	}

	cmd := exec.Command(ai.BinaryPath, args...)
	cmd.Dir = projectRoot // è®¾ç½®å·¥ä½œç›®å½•

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("é¡¹ç›®åœ°å›¾ç”Ÿæˆå¤±è´¥: %v", err)
	}

	// è¯»å–è¾“å‡ºæ–‡ä»¶
	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–åœ°å›¾ç»“æœå¤±è´¥: %v", err)
	}

	var result MapResult
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("è§£æåœ°å›¾ç»“æœå¤±è´¥: %v", err)
	}

	return &result, nil
}

// SearchSymbol æœç´¢ç¬¦å· (--mode query)
func (ai *ASTIndexer) SearchSymbol(projectRoot string, query string) (*QueryResult, error) {
	return ai.SearchSymbolWithScope(projectRoot, query, "")
}

// SearchSymbolWithScope å¸¦èŒƒå›´çš„ç¬¦å·æœç´¢
func (ai *ASTIndexer) SearchSymbolWithScope(projectRoot string, query string, scope string) (*QueryResult, error) {
	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, "query")

	// æ¸…ç†æ—§æ–‡ä»¶
	_ = os.Remove(outputPath)

	args := []string{
		"--mode", "query",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
		"--query", query,
	}
	if scope != "" {
		args = append(args, "--scope", scope)
	}

	cmd := exec.Command(ai.BinaryPath, args...)
	cmd.Dir = projectRoot

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("ç¬¦å·æœç´¢å¤±è´¥: %v", err)
	}

	// è¯»å–è¾“å‡ºæ–‡ä»¶
	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–æœç´¢ç»“æœå¤±è´¥: %v", err)
	}

	var result QueryResult
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("è§£ææœç´¢ç»“æœå¤±è´¥: %v", err)
	}

	return &result, nil
}

// GetSymbolAtLine è·å–æŒ‡å®šæ–‡ä»¶è¡Œå·å¤„çš„ç¬¦å·ä¿¡æ¯ (--mode query --file --line)
func (ai *ASTIndexer) GetSymbolAtLine(projectRoot string, filePath string, line int) (*Node, error) {
	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, fmt.Sprintf("line_%d", line))

	// æ¸…ç†æ‰€æœ‰æ—§çš„ line_*.json ä¸´æ—¶æ–‡ä»¶ï¼ˆé¿å…æ³„æ¼ï¼‰
	mcpData := filepath.Join(projectRoot, ".mcp-data")
	if entries, err := os.ReadDir(mcpData); err == nil {
		for _, e := range entries {
			if !e.IsDir() && strings.HasPrefix(e.Name(), ".ast_result_line_") && strings.HasSuffix(e.Name(), ".json") {
				_ = os.Remove(filepath.Join(mcpData, e.Name()))
			}
		}
	}

	// æ¸…ç†å½“å‰æ–‡ä»¶
	_ = os.Remove(outputPath)

	args := []string{
		"--mode", "query",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
		"--file", filePath,
		"--line", fmt.Sprintf("%d", line),
	}

	cmd := exec.Command(ai.BinaryPath, args...)
	cmd.Dir = projectRoot

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("å®šä½ç¬¦å·å¤±è´¥: %v", err)
	}

	// è¯»å–è¾“å‡ºæ–‡ä»¶
	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–å®šä½ç»“æœå¤±è´¥: %v", err)
	}

	var result QueryResult
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("è§£æå®šä½ç»“æœå¤±è´¥: %v", err)
	}

	return result.FoundSymbol, nil
}

// Analyze æ‰§è¡Œå½±å“åˆ†æ (--mode analyze)
func (ai *ASTIndexer) Analyze(projectRoot string, symbol string, direction string) (*ImpactResult, error) {
	// å…ˆç¡®ä¿ç´¢å¼•æ˜¯æœ€æ–°çš„
	_, _ = ai.EnsureFreshIndex(projectRoot)

	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, "analyze")

	// æ¸…ç†æ—§æ–‡ä»¶
	_ = os.Remove(outputPath)

	args := []string{
		"--mode", "analyze",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
		"--query", symbol,
	}
	if direction != "" {
		args = append(args, "--direction", direction)
	}

	cmd := exec.Command(ai.BinaryPath, args...)
	cmd.Dir = projectRoot

	if err := cmd.Run(); err != nil {
		return nil, fmt.Errorf("å½±å“åˆ†ææ‰§è¡Œå¤±è´¥: %v", err)
	}

	// è¯»å–è¾“å‡ºæ–‡ä»¶
	data, err := os.ReadFile(outputPath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–åˆ†æç»“æœå¤±è´¥: %v", err)
	}

	var result ImpactResult
	if err := json.Unmarshal(data, &result); err != nil {
		return nil, fmt.Errorf("è§£æåˆ†æç»“æœå¤±è´¥: %v", err)
	}

	return &result, nil
}

func (ai *ASTIndexer) runIndexCommand(projectRoot string, args []string) error {
	timeout := getIndexCommandTimeout()
	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()

	cmd := exec.CommandContext(ctx, ai.BinaryPath, args...)
	cmd.Dir = projectRoot
	output, err := cmd.CombinedOutput()
	if ctx.Err() == context.DeadlineExceeded {
		msg := strings.TrimSpace(string(output))
		if msg != "" {
			return fmt.Errorf("ç´¢å¼•å‘½ä»¤è¶…æ—¶(%s): %s", timeout, msg)
		}
		return fmt.Errorf("ç´¢å¼•å‘½ä»¤è¶…æ—¶(%s)", timeout)
	}
	if err != nil {
		msg := strings.TrimSpace(string(output))
		if msg != "" {
			return fmt.Errorf("%v: %s", err, msg)
		}
		return err
	}
	return nil
}

func buildIndexArgs(projectRoot, dbPath, outputPath, ignoreDirs, extensions, scope string, useExtensions bool, forceFull bool) []string {
	args := []string{
		"--mode", "index",
		"--project", projectRoot,
		"--db", dbPath,
		"--output", outputPath,
	}
	if forceFull {
		args = append(args, "--force-full")
	}
	if scope != "" {
		args = append(args, "--scope", scope)
	}
	if ignoreDirs != "" {
		args = append(args, "--ignore-dirs", ignoreDirs)
	}
	if useExtensions && extensions != "" {
		args = append(args, "--extensions", extensions)
	}
	return args
}

// Index åˆ·æ–°ç´¢å¼• (--mode index)
func (ai *ASTIndexer) Index(projectRoot string) (*IndexResult, error) {
	return ai.indexWithOptions(projectRoot, "", false)
}

// IndexFull å¼ºåˆ¶å…¨é‡ç´¢å¼•ï¼ˆç¦ç”¨ bootstrapï¼‰
func (ai *ASTIndexer) IndexFull(projectRoot string) (*IndexResult, error) {
	return ai.indexWithOptions(projectRoot, "", true)
}

func (ai *ASTIndexer) indexWithOptions(projectRoot string, scope string, forceFull bool) (*IndexResult, error) {
	dbPath := getDBPath(projectRoot)
	outputPath := getOutputPath(projectRoot, "index")

	// ç¡®ä¿ .mcp-data ç›®å½•å­˜åœ¨
	mcpData := filepath.Join(projectRoot, ".mcp-data")
	_ = os.MkdirAll(mcpData, 0755)
	// æ¸…ç†æ—§æ–‡ä»¶
	_ = os.Remove(outputPath)

	// æŠ€æœ¯æ ˆæ£€æµ‹ä»…ç”¨äºå¿½ç•¥ç›®å½•ä¸å¤±è´¥å…œåº•ï¼Œä¸å†é»˜è®¤å¯ç”¨æ‰©å±•ç™½åå•
	extensions, ignoreDirs := detectTechStackAndConfig(projectRoot)

	// ç¬¬ä¸€é˜¶æ®µï¼šé»˜è®¤å…¨é‡æ‰«æï¼ˆä¸ä¼  --extensionsï¼‰ï¼Œè®© Rust ç«¯æŒ‰çœŸå®æ–‡ä»¶æ‰©å±•è‡ªé€‚åº”
	args := buildIndexArgs(projectRoot, dbPath, outputPath, ignoreDirs, extensions, scope, false, forceFull)
	if err := ai.runIndexCommand(projectRoot, args); err != nil {
		// ç¬¬äºŒé˜¶æ®µï¼šä»…åœ¨å…¨é‡æ‰«æå¤±è´¥æ—¶ï¼Œé€€å›åˆ°æ‰©å±•ç™½åå•æ¨¡å¼
		if extensions != "" {
			_ = os.Remove(outputPath)
			retryArgs := buildIndexArgs(projectRoot, dbPath, outputPath, ignoreDirs, extensions, scope, true, forceFull)
			if retryErr := ai.runIndexCommand(projectRoot, retryArgs); retryErr != nil {
				return nil, fmt.Errorf("ç´¢å¼•åˆ·æ–°å¤±è´¥: å…¨é‡æ‰«æå¤±è´¥(%v); æ‰©å±•æ¨¡å¼é‡è¯•å¤±è´¥(%v)", err, retryErr)
			}
		} else {
			return nil, fmt.Errorf("ç´¢å¼•åˆ·æ–°å¤±è´¥: %v", err)
		}
	}

	// è¯»å–è¾“å‡ºæ–‡ä»¶
	data, err := os.ReadFile(outputPath)
	if err != nil {
		// ç´¢å¼•å¯èƒ½ä¸è¾“å‡ºæ–‡ä»¶ï¼Œè¿”å›é»˜è®¤ç»“æœ
		result := &IndexResult{Status: "success"}
		ai.markIndexFresh(projectRoot)
		return result, nil
	}

	var result IndexResult
	if err := json.Unmarshal(data, &result); err != nil {
		fallback := &IndexResult{Status: "success"}
		ai.markIndexFresh(projectRoot)
		return fallback, nil
	}

	ai.markIndexFresh(projectRoot)
	return &result, nil
}

// IndexScope æŒ‰ç›®å½•èŒƒå›´å¢é‡åˆ·æ–°ç´¢å¼•ï¼ˆç”¨äºçƒ­ç‚¹è¡¥å½•ï¼‰
func (ai *ASTIndexer) IndexScope(projectRoot string, scope string) (*IndexResult, error) {
	scope = strings.TrimSpace(scope)
	if scope == "" || scope == "." || scope == "./" {
		return ai.Index(projectRoot)
	}
	return ai.indexWithOptions(projectRoot, scope, false)
}

// AnalyzeNamingStyle åˆ†æé¡¹ç›®å‘½åé£æ ¼
func (ai *ASTIndexer) AnalyzeNamingStyle(projectRoot string) (*NamingAnalysis, error) {
	// 1. ç¡®ä¿ç´¢å¼•å­˜åœ¨ (ä¸”å°è¯•åˆ·æ–°)
	if _, err := ai.EnsureFreshIndex(projectRoot); err != nil {
		// å¦‚æœç´¢å¼•å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¯»å–ç°æœ‰æ•°æ®åº“
		// ä»€ä¹ˆä¹Ÿä¸åš
	}

	dbPath := getDBPath(projectRoot)
	if !fileExists(dbPath) {
		return &NamingAnalysis{IsNewProject: true}, nil
	}

	db, err := sql.Open("sqlite", dbPath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€æ•°æ®åº“å¤±è´¥: %v", err)
	}
	defer db.Close()

	// 2. ç»Ÿè®¡æ–‡ä»¶æ•°
	var fileCount int
	if err := db.QueryRow("SELECT COUNT(*) FROM files").Scan(&fileCount); err != nil {
		// å¯èƒ½è¡¨ä¸å­˜åœ¨
		return &NamingAnalysis{IsNewProject: true}, nil
	}

	if fileCount < 3 {
		return &NamingAnalysis{IsNewProject: true, FileCount: fileCount}, nil
	}

	// 3. æå–æ‰€æœ‰å‡½æ•°å
	rows, err := db.Query("SELECT name FROM symbols WHERE symbol_type IN ('function', 'method') LIMIT 1000")
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢ç¬¦å·å¤±è´¥: %v", err)
	}
	defer rows.Close()

	var funcNames []string
	var snakeCount, camelCount int
	// reSnake := regexp.MustCompile(`^[a-z0-9_]+$`) // Unused
	reCamel := regexp.MustCompile(`^[a-z][a-zA-Z0-9]*$`)

	prefixCounts := make(map[string]int)

	for rows.Next() {
		var name string
		rows.Scan(&name)
		funcNames = append(funcNames, name)

		// é£æ ¼åˆ¤å®š
		if strings.Contains(name, "_") && strings.ToLower(name) == name {
			snakeCount++
		} else if reCamel.MatchString(name) && !strings.Contains(name, "_") {
			camelCount++
		}

		// å‰ç¼€æå– (å¦‚ get_, set_, on_)
		parts := strings.Split(name, "_")
		if len(parts) > 1 {
			prefixCounts[parts[0]+"_"]++
		} else if strings.HasPrefix(name, "get") && len(name) > 3 && name[3] >= 'A' && name[3] <= 'Z' {
			prefixCounts["get"]++ // camelCase get
		}
	}

	// 4. è®¡ç®—ç»“æœ
	totalFuncs := len(funcNames)
	if totalFuncs == 0 {
		return &NamingAnalysis{IsNewProject: true, FileCount: fileCount}, nil
	}

	snakePct := float64(snakeCount) / float64(totalFuncs) * 100
	camelPct := float64(camelCount) / float64(totalFuncs) * 100

	style := "snake_case"
	if camelCount > snakeCount {
		style = "camelCase"
	} else if snakeCount == 0 && camelCount == 0 {
		style = "mixed"
	}

	// æå–Topå‰ç¼€
	var prefixes []string
	for p, c := range prefixCounts {
		if c > max(2, totalFuncs/20) { // è‡³å°‘å‡ºç°2æ¬¡ä¸”å æ¯”>5%
			prefixes = append(prefixes, p)
		}
	}
	// ç®€å•å–å‰5ä¸ªä½œä¸ºå±•ç¤º
	if len(prefixes) > 5 {
		prefixes = prefixes[:5]
	}

	// æ ·ä¾‹æ•°æ® (å–å‰10ä¸ª)
	var samples []string
	if totalFuncs > 10 {
		samples = funcNames[:10]
	} else {
		samples = funcNames
	}

	return &NamingAnalysis{
		FileCount:      fileCount,
		SymbolCount:    totalFuncs,
		DominantStyle:  style,
		SnakeCasePct:   fmt.Sprintf("%.1f%%", snakePct),
		CamelCasePct:   fmt.Sprintf("%.1f%%", camelPct),
		ClassStyle:     "PascalCase", // é»˜è®¤å‡è®¾
		CommonPrefixes: prefixes,
		SampleNames:    samples,
		IsNewProject:   false,
	}, nil
}

// RiskInfo é£é™©ä¿¡æ¯
type RiskInfo struct {
	SymbolName string  `json:"symbol_name"`
	Score      float64 `json:"score"`
	Reason     string  `json:"reason"`
}

// ComplexityReport å¤æ‚åº¦æŠ¥å‘Š
type ComplexityReport struct {
	HighRiskSymbols []RiskInfo `json:"high_risk_symbols"`
	TotalAnalyzed   int        `json:"total_analyzed"`
}

// AnalyzeComplexity åˆ†æç¬¦å·å¤æ‚åº¦ (åŸºäºè°ƒç”¨å…³ç³»)
// ç®€å•çš„ä¸­å¿ƒåº¦åˆ†æï¼šFan-out (å‡ºåº¦) é«˜ä»£è¡¨ä¾èµ–å¤æ‚ï¼ŒFan-in (å…¥åº¦) é«˜ä»£è¡¨å½±å“èŒƒå›´å¹¿/è´£ä»»é‡
func (ai *ASTIndexer) AnalyzeComplexity(projectRoot string, symbolNames []string) (*ComplexityReport, error) {
	if len(symbolNames) == 0 {
		return &ComplexityReport{}, nil
	}

	dbPath := getDBPath(projectRoot)
	if !fileExists(dbPath) {
		return nil, nil // No DB, no analysis
	}

	db, err := sql.Open("sqlite", dbPath)
	if err != nil {
		return nil, err
	}
	defer db.Close()

	var report ComplexityReport
	report.TotalAnalyzed = len(symbolNames)

	hasCalleeID := hasColumn(db, "calls", "callee_id")

	for _, name := range symbolNames {
		// 1. è·å– Symbol ä¿¡æ¯ï¼ˆID + canonical_idï¼‰
		rows, err := db.Query("SELECT symbol_id, symbol_type, canonical_id FROM symbols WHERE name = ?", name)
		if err != nil {
			continue
		}

		type symbolRef struct {
			id          int
			canonicalID string
		}
		var symbols []symbolRef
		for rows.Next() {
			var s symbolRef
			var sType string
			if err := rows.Scan(&s.id, &sType, &s.canonicalID); err != nil {
				continue
			}
			if sType == "function" || sType == "method" || sType == "class" {
				symbols = append(symbols, s)
			}
		}
		rows.Close()

		if len(symbols) == 0 {
			continue
		}

		// èšåˆæ‰€æœ‰åŒåç¬¦å·çš„æŒ‡æ ‡
		var maxFanIn, maxFanOut int

		for _, sym := range symbols {
			// Fan-out: æˆ‘è°ƒç”¨äº†è° (caller_id = symbol_id)
			var fanOut int
			db.QueryRow("SELECT COUNT(*) FROM calls WHERE caller_id = ?", sym.id).Scan(&fanOut)
			if fanOut > maxFanOut {
				maxFanOut = fanOut
			}

			// Fan-in: ä¼˜å…ˆ callee_idï¼Œå›é€€ callee_name
			var fanIn int
			if hasCalleeID {
				db.QueryRow(
					"SELECT COUNT(*) FROM calls WHERE callee_id = ? OR (callee_id IS NULL AND callee_name = ?)",
					sym.canonicalID, name,
				).Scan(&fanIn)
			} else {
				db.QueryRow("SELECT COUNT(*) FROM calls WHERE callee_name = ?", name).Scan(&fanIn)
			}
			if fanIn > maxFanIn {
				maxFanIn = fanIn
			}
		}

		// ç®€å•çš„è¯„åˆ†æ¨¡å‹
		// FanOut > 10 -> Complex Logic
		// FanIn > 20 -> High Impact Core
		score := float64(maxFanOut)*1.0 + float64(maxFanIn)*0.5

		var reasons []string
		if maxFanOut > 10 {
			reasons = append(reasons, fmt.Sprintf("High Coupling (Calls: %d)", maxFanOut))
		}
		if maxFanIn > 20 {
			reasons = append(reasons, fmt.Sprintf("Core Module (Ref by: %d)", maxFanIn))
		}

		// ğŸ†• å§‹ç»ˆæ·»åŠ åˆ°æŠ¥å‘Šï¼Œå³ä½¿å¤æ‚åº¦å¾ˆä½
		report.HighRiskSymbols = append(report.HighRiskSymbols, RiskInfo{
			SymbolName: name,
			Score:      score,
			Reason:     strings.Join(reasons, ", "),
		})
	}

	return &report, nil
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

func hasColumn(db *sql.DB, table string, column string) bool {
	q := fmt.Sprintf("SELECT COUNT(*) FROM pragma_table_info('%s') WHERE name = ?", table)
	var n int
	if err := db.QueryRow(q, column).Scan(&n); err != nil {
		return false
	}
	return n > 0
}
